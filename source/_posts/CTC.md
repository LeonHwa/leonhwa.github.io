---
title: CTC
date: 2020-01-05 15:15:00
tags: DL
---
CTCæ˜¯åºåˆ—æ ‡æ³¨é—®é¢˜ä¸­çš„ä¸€ç§æŸå¤±å‡½æ•°ã€‚

ä¼ ç»Ÿåºåˆ—æ ‡æ³¨ç®—æ³•éœ€è¦æ¯ä¸€æ—¶åˆ»è¾“å…¥ä¸è¾“å‡ºç¬¦å·å®Œå…¨å¯¹é½ã€‚è€ŒCTCæ‰©å±•äº†æ ‡ç­¾é›†åˆï¼Œæ·»åŠ ç©ºå…ƒç´ ã€‚

ctcç”¨äºè®­ç»ƒé˜¶æ®µ

## CTC loss

è¦ç‚¹ï¼š

1. çŸ©é˜µ ğ›¼(å‰å‘å˜é‡)ç”¨äºè®¡ç®—loss
2.  çŸ©é˜µğ›½ (åå‘å˜é‡)ç”¨æ¥æ–¹ä¾¿è®¡ç®—gradients.



ç¬¦å·è¡¨ç¤ºï¼š

1. $y_k^t$ä»£è¡¨è¾“å‡ºåºåˆ—åœ¨ç¬¬tæ­¥è¾“å‡ºä¸º**kå­—ç¬¦**çš„æ¦‚ç‡ï¼Œä¸¾ä¸ªç®€å•çš„ä¾‹å­ï¼šå½“è¾“å‡ºçš„åºåˆ—ä¸º$(a-ab-)$æ—¶ï¼Œ$y_a^3$ ä»£è¡¨äº†åœ¨ç¬¬3æ­¥è¾“å‡ºçš„å­—æ¯ä¸ºaçš„æ¦‚ç‡ï¼›(ä¸‹é¢çš„ä¾‹å­ç”¨apple åŠ _ å³ a, p, l ,e, _,äº”ä¸ªå­—ç¬¦ä¸¾ä¾‹ï¼Œ ä½†æ˜¯æ˜ å°„è¡¨ä¸­å¯¹åº”çš„å­—ç¬¦ä¼šæœ‰å¤šä¸ª)

2. $p(\pi | x)$ä»£è¡¨äº†ç»™å®šè¾“å…¥$x$ï¼Œè¾“å‡ºè·¯å¾„ä¸º $\pi$ çš„æ¦‚ç‡ï¼›

   ç”±äºå‡è®¾åœ¨æ¯ä¸€ä¸ªæ—¶é—´æ­¥è¾“å‡ºçš„labelçš„æ¦‚ç‡éƒ½æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼Œé‚£ä¹ˆ $p(\pi | x)$ç”¨å…¬å¼æ¥è¡¨ç¤ºä¸º :

   

   $$p(\pi | x) = \prod_{t=1}^{T}(y_k^t) \tag{1}$$

   

3. $\mathscr{F}$ ä»£è¡¨ä¸€ç§å¤šå¯¹ä¸€çš„æ˜ å°„ï¼Œå°†è¾“å‡ºè·¯å¾„ $\pi$ æ˜ å°„åˆ° æ ‡ç­¾åºåˆ— $l$ çš„ä¸€ç§å˜æ¢ï¼Œä¸¾ä¸ªç®€å•çš„ä¾‹å­ $\mathscr{F}(a-ab-) = \mathscr{F}(-aa--abb) = aab$ï¼ˆå…¶ä¸­-ä»£è¡¨äº†ç©ºæ ¼)

4. $p(l \mid  x)$ä»£è¡¨äº†ç»™å®šè¾“å…¥$x$ï¼Œè¾“å‡ºä¸ºåºåˆ—$l$çš„æ¦‚ç‡:

   å› æ­¤è¾“å‡ºçš„åºåˆ—ä¸º $l$ çš„æ¦‚ç‡å¯ä»¥è¡¨ç¤ºä¸ºæ‰€æœ‰è¾“å‡ºçš„è·¯å¾„ $\pi$ æ˜ å°„åçš„åºåˆ—ä¸º $l$ çš„æ¦‚ç‡ä¹‹å’Œï¼Œç”¨å…¬å¼è¡¨ç¤ºä¸º:

   

    $$p(l | x) = \sum_{\pi \subseteq {\mathscr{F}^{-1}(l)}} p(\pi|x) \tag{2}$$

   

   å…¶ä¸­$\pi \subseteq {\mathscr{F}^{-1}}(l) $ è¡¨ç¤ºåœ¨è·¯å¾„æœ‰å¤šä¸ªè·¯å¾„$\pi$ å¯¹åº”ç›¸åŒçš„è¾“å‡ºåºåˆ—$l$,$\mathscr{F}(\pi) = l$



### å‰å‘åå‘ç®—æ³•ï¼ˆè®­ç»ƒé˜¶æ®µï¼‰

å‘å‰ç®—æ³•è¦è§£å†³çš„å°±æ˜¯å¯¹çœŸå®è¾“å‡ºåºåˆ—çš„æ‰€æœ‰è·¯å¾„æ¦‚ç‡æ±‚å’Œï¼ˆå…¬å¼2ï¼‰ï¼Œç›´æ¥æš´åŠ›è®¡ç®—$p(l\mid x)$çš„å¤æ‚åº¦éå¸¸é«˜ï¼Œä½œè€…å€Ÿé‰´HMMçš„Forward-Backwardç®—æ³•æ€è·¯ï¼Œåˆ©ç”¨åŠ¨æ€è§„åˆ’ç®—æ³•æ±‚è§£ã€‚

ä¸ºäº†æ›´å½¢è±¡è¡¨ç¤ºé—®é¢˜çš„æœç´¢ç©ºé—´ï¼Œç”¨Xè½´è¡¨ç¤ºæ—¶é—´åºåˆ—ï¼Œ Yè½´è¡¨ç¤ºè¾“å‡ºåºåˆ—ï¼Œå¹¶æŠŠè¾“å‡ºåºåˆ—åšæ ‡å‡†åŒ–å¤„ç†ï¼Œè¾“å‡ºåºåˆ—ä¸­é—´å’Œå¤´å°¾éƒ½åŠ ä¸Šblankï¼Œç”¨$l$è¡¨ç¤ºæœ€ç»ˆæ ‡ç­¾ï¼Œ$l'$è¡¨ç¤ºæ‰©å±•åçš„å½¢å¼ï¼Œåˆ™ç”±$2|l| + 1 = 2|lâ€™|$ï¼Œæ¯”å¦‚$l=apple \Rightarrow l'= \_a\_p\_p\_l\_e\_$



ä¸ºäº†ç†è§£å‘å‰ç®—æ³•ï¼Œ å¯ä»¥æ„å»ºè¡¨æ ¼æ¥ç†è§£ï¼Œå°†çœŸå®æ ‡ç­¾åºåˆ—$l$è½¬æ¢ä¸º$l'$ä½œä¸ºçºµåæ ‡ï¼ˆç”±ä¸Šè‡³ä¸‹å¢å¤§ï¼‰ï¼Œæ¨ªè½´ä¸ºæ—¶é—´åºåˆ—ï¼ˆç”±å·¦è‡³å³å¢å¤§ï¼‰ã€‚

çº¦æŸæ¡ä»¶ï¼š

1. è½¬æ¢åªèƒ½å¾€å³ä¸‹æ–¹å‘ï¼Œå…¶ä»–æ–¹å‘ä¸å…è®¸
2. ç›¸åŒçš„å­—ç¬¦ä¹‹é—´èµ·ç è¦æœ‰ä¸€ä¸ªç©ºå­—ç¬¦
3. éç©ºå­—ç¬¦ä¸èƒ½è·³è¿‡
4. èµ·ç‚¹å¿…é¡»ä»å‰ä¸¤ä¸ªå­—ç¬¦å¼€å§‹
5. ç»ˆç‚¹å¿…é¡»è½åœ¨ç»“å°¾ä¸¤ä¸ªå­—ç¬¦

![ctc_1](/images/ctc_9.png)

ç›¸å…³ç»†èŠ‚å¯ä»¥å‚è€ƒhttps://xiaodu.io/ctc-explained/



#### å‘å‰ä¼ æ’­å…¬å¼ï¼š

**ç¬¦å·è¡¨ç¤º**ï¼š

$ seq(s)$ï¼š çºµè½´ç”±ä¸Šå¾€ä¸‹ç¬¬sä¸ªå­—ç¬¦

$\alpha_t(s) $:   tæ—¶åˆ»ç»è¿‡èŠ‚ç‚¹sçš„å…¨éƒ¨å‰ç¼€è·¯å¾„çš„æ¦‚ç‡æ€»å’Œ

1. å½“seq(s)ä¸ºç©ºç¬¦å·æˆ–seq(s) ç­‰äºseq(s-1)æ—¶

   $$\alpha_t(s) = (\alpha_{t-1}(s) + \alpha_{t-1}(s-1)) \cdot y_{seq(s)}^t$$

<img src="/images/ctc_blank.png" alt="ctc_blank" style="zoom:40%;" />

<img src="/images/ctc_same.png" alt="ctc_same" style="zoom:40%;" />

1. å¦åˆ™ï¼š

   $$\alpha_t(s) = (\alpha_{t-1}(s) + \alpha_{t-1}(s-1) +\alpha_{t-1}(s-2)) \cdot y_{seq(s)}^t$$

<img src="/images/ctc_other.png" alt="ctc_other" style="zoom:40%;" />

3. åˆå§‹ï¼š

   $$\alpha_1(1) = y_{\_}^{1}, \alpha_1(2) = y_{seq(2)}^{1}, \alpha_1(s) = 0, \forall s > 2$$

 **CTC Loss**

å¯¹äºä¸Šå›¾appleè¯æ±‡çš„ä¾‹å­

$$- \boldsymbol{ln}(p(apple | x)) =  -\boldsymbol{ln}(\alpha_8(10) + \alpha_8(11))$$

é€šç”¨å…¬å¼è¡¨ç¤ºä¸º:

$$- \boldsymbol{ln}(p(l | x)) =  -\boldsymbol{ln}(\alpha_T(|l'| - 1) + \alpha_T(|l'|)) \tag{3}$$



#### å‘åä¼ æ’­å…¬å¼ï¼š

åŸºæœ¬å’Œå‘å‰å…¬å¼ä¸€æ · ï¼Œä¸è¿‡æ˜¯åæ–¹å‘çš„

**ç¬¦å·è¡¨ç¤º**ï¼š

$\beta_t(s) $:   tæ—¶åˆ»ç»è¿‡èŠ‚ç‚¹sçš„å…¨éƒ¨åç¼€è·¯å¾„çš„æ¦‚ç‡æ€»å’Œ

1. å½“seq(s)ä¸ºç©ºç¬¦å·æˆ–seq(s) ç­‰äºseq(s-1)æ—¶

   $$\beta_t(s) = (\beta_{t+1}(s) + \beta_{t+1}(s+1)) \cdot y_{seq(s)}^t$$

2. å¦åˆ™ï¼š

   $$\beta_t(s) = (\beta_{t+1}(s) + \beta_{t+1}(s+1) +\beta_{t+1}(s+2)) \cdot  y_{seq(s)}^t $$

3. åˆå§‹ï¼š

   $$\beta_T(|l'|) = y_{\_}^{T}, \beta_T(|l'| - 1) = y_{seq(|l'| - 1)}^{T}, \beta_T(s) = 0, \forall s < |l'| - 1$$

 **CTC Loss**

å¯¹äºä¸Šå›¾appleè¯æ±‡çš„ä¾‹å­

$$- \boldsymbol{ln}(p(apple | x)) =  -\boldsymbol{ln}(\beta_1(1) + \beta_2(2))$$

é€šç”¨å…¬å¼è¡¨ç¤ºä¸º:

$$- \boldsymbol{ln}(p(l | x)) =  -\boldsymbol{ln}(\beta_1(1) + \beta_2(2)) \tag{4}$$



#### å‘å‰å‘åå…¬å¼ç»“åˆ



åœ¨ä»»æ„tæ—¶åˆ»ï¼Œä¾¿åˆ©æ‰€æœ‰çš„s,å³å¯å¾—åˆ°å…¨éƒ¨è·¯å¾„çš„æ€»å’Œ

$$\boldsymbol{p}(\boldsymbol{l} | \boldsymbol{x})=\sum_{\boldsymbol{s}=1}^{\left|\boldsymbol{l}^{\prime}\right|} \frac{\boldsymbol{\alpha}_{\mathrm{t}}(\boldsymbol{s}) \boldsymbol{\beta}_{\boldsymbol{t}}(\boldsymbol{s})}{\boldsymbol{y}_{l_{\boldsymbol{s}}^{'}}^{t}} \tag{5}$$

**å…¬å¼ä¸­çš„tæ˜¯ä»»é€‰çš„**

(é™¤ä»¥ $y_{l_{s}^{'}}^t$ å› ä¸ºåœ¨ $\alpha$ å’Œ $\beta$ ä¸­ä¹˜äº†ä¸¤æ¬¡)ã€‚

![ctc_10](/images/ctc_10.png)



## å¯¼æ•°

### é˜²æ­¢å‚æ•°underflow

åœ¨Alex Gravesçš„[è®ºæ–‡](http://www.cs.toronto.edu/~graves/icml_2006.pdf)ä¸­, ä¸ºäº†é˜²æ­¢å‚æ•°underflowï¼Œè¦å¯¹$\alpha_t(s), \beta_t(s)$è¿›è¡Œæ ‡å‡†åŒ–è½¬æ¢

$$C_{t} \stackrel{\text { def }}{=} \sum_{s} \alpha_{t}(s), \quad \quad \hat{\alpha}_{t}(s) \stackrel{\text { def }}{=} \frac{\alpha_{t}(s)}{C_{t}}$$

$$D_{t} \stackrel{\text { def }}{=} \sum_{s} \alpha_{t}(s), \quad \quad \hat{\alpha}_{t}(s) \stackrel{\text { def }}{=} \frac{\alpha_{t}(s)}{D_{t}}$$

Loss å‡½æ•°ä¹Ÿç”±$- \boldsymbol{ln}(p(l | x)) =  -\boldsymbol{ln}(\alpha_T(|l'| - 1) + \alpha_T(|l'|))$å˜æˆäº†:

$- \boldsymbol{ln}(p(l | x)) =  - \sum_{t = 1}^{t} ln(C_t)$



### Softmax å‡½æ•°æ±‚å¯¼

è®¾ $X = [x_1,x_2,...,x_n]$ ï¼Œ$Y = [y_1, y_2,...,y_n], Y = softmax(X)$ 

$$ y_i = \frac{e^{x_i}}{\sum_{j = 1}e^{x_j}} \tag{6}$$

(1) å½“ $i = j$ æ—¶

$$\begin{aligned} \frac{\partial y_{i}}{\partial x_{j}} &=\frac{\partial y_{i}}{\partial x_{i}} \\ &=\frac{\partial}{\partial x_{i}}\left(\frac{e^{x_{i}}}{\sum_{k} e^{x_{k}}}\right) \\ &=\frac{\left(e^{x_{i}}\right)^{\prime}\left(\sum_{k} e^{x_{k}}\right)-e^{x_{i}}\left(\sum_{k} e^{x_{k}}\right)^{\prime}}{\left(\sum_{k} e^{x_{k}}\right)^{2}} \\ &=\frac{e^{x_{i}} \cdot\left(\sum_{k} e^{x_{k}}\right)^{2}}{\left(\sum_{k} e^{x_{k}}\right)^{2}} \\ &=\frac{e^{x_{i}} \cdot\left(\sum_{k} e^{x_{k}}\right)}{\left(\sum_{k} e^{x_{k}}\right)^{2}}-\frac{e^{x_{i}} \cdot e^{x_{i}}}{\sum_{k} e^{x_{k}}} \\ &=\frac{e^{x_{i}} \cdot\left(\sum_{i} \cdot y_{i}\right.}{\sum_{k} e^{x_{k}}} \cdot \frac{e^{x_{i}}}{\sum_{k} e_{k}^{x_{k}}} \\ &=y_{i}\left(1-y_{i}\right) \end{aligned}$$

(1) å½“ $i \neq  j$ æ—¶

$$\begin{aligned} \frac{\partial y_{i}}{\partial x_{j}} &=\frac{\partial}{\partial x_{j}}\left(\frac{e^{x_{i}}}{\sum_{k} e^{x_{k}}}\right) \\ &=\frac{\left(e^{x_{i}}\right)^{\prime}\left(\sum_{k} e^{x_{k}}\right)}{\left(\sum_{k} e^{x_{k}}\right)^{2}} \\ &=\frac{0 \cdot\left(\sum_{k} e^{x_{k}}\right)-e^{x_{i}} \cdot e^{x_{j}}}{\left(\sum_{k} e^{x_{k}}\right)^{2}} \\ &=\frac{-e^{x_{i}} \cdot e^{x_{j}}}{\left(\sum_{k} e^{x_{k}}\right)^{2}} \\ &=-\frac{e^{x_{i}}}{\sum_{k} e^{x_{k}}} \cdot \frac{e^{x_{j}}}{\sum_{k} e^{x_{k}}} \\ &=-y_{i} \cdot y_{j} \end{aligned}$$

ç»¼ä¸Šæ‰€è¿°ï¼š$\frac{\partial y_{i}}{\partial x_{j}}=\left\{\begin{array}{l}{=y_{i}-y_{i} y_{i}},å½“i = j  \\ {=0-y_{i} \cdot y_{j}} å½“i \neq j \end{array}\right.$



### ctcæ±‚å¯¼

ç”±ä¸Šé¢å…¬å¼3å…¬å¼5ï¼š

$$- \boldsymbol{ln}(p(l | x)) =  -\boldsymbol{ln}(\alpha_T(|l'| - 1) + \alpha_T(|l'|)) \tag{3}$$

$$\boldsymbol{p}(\boldsymbol{l} | \boldsymbol{x})=\sum_{\boldsymbol{s}=1}^{\left|\boldsymbol{l}^{\prime}\right|} \frac{\boldsymbol{\alpha}_{\mathrm{t}}(\boldsymbol{s}) \boldsymbol{\beta}_{\boldsymbol{t}}(\boldsymbol{s})}{\boldsymbol{y}_{l_{\boldsymbol{s}}^{'}}^{t}} (tæ˜¯ä»»æ„çš„) \tag{5}$$

æ³¨æ„åˆ° è¿™é‡Œç¬”è®°çš„

x----RNN(x) -->$u_k^t$ ---softmax(u)--->  $y_k^t$   (kè¡¨ç¤ºçš„æ˜¯å­—ç¬¦ï¼Œæ˜¯æ¨¡å‹ä¸­å­—æ¯æ˜ å°„è¡¨ä¸­çš„ä¸€ä¸ªï¼Œ$t \subseteq  T$ï¼Œ$T$æ˜¯rnnè¾“å‡ºçš„åºåˆ—çš„ä¸ªæ•°)

$$\frac{\partial \ln (p(\mathbf{l} | \mathbf{x}))}{\partial y_{k}^{t}}=\frac{1}{p(\mathbf{l} | \mathbf{x})} \frac{\partial p(\mathbf{l} | \mathbf{x})}{\partial y_{k}^{t}} \tag{7}$$

å®šä¹‰$lab(l,k) = \{s: l_s^{'} = k\}$ ï¼Œ $ lab(l,k)$å¯èƒ½ä¸ºç©º, å› ä¸ºRNNè¾“å‡ºçš„åºåˆ—çš„é•¿åº¦T ç»è¿‡ctc è½¬æ¢åå˜ä¸º$l$, $l \leqslant  T$
å­—æ¯è¡¨ä¸­çš„å­—ç¬¦k ä¸ä¸€å®šä¼šåœ¨ctcæ˜ å°„çš„æ–‡æœ¬ä¸­ã€‚

$$\frac{\partial p(l|x)}{ \partial y_k^t} = \frac{1}{y_k^{t^2}} \sum_{s \in lab(l,k)} \alpha_t(s) \beta_t(x) \tag{8}$$

å…·ä½“æ±‚å¯¼å¦‚ä¸‹ï¼š

![ctc_partial](/images/ctc_partial.png)



æ ¹æ®å‰é¢æ‰€è¯´çš„é˜²æ­¢underflow å…¬å¼å¯ä»¥è½¬æ¢å¦‚ä¸‹ï¼š

$$-\frac{\partial ln(p(l|x))}{ \partial u_k^t}=y_{k}^{t}-\frac{1}{y_{k}^{t} Z_{t}} \sum_{s \in \operatorname{lab}(\mathbf{l}, k)} \hat{\alpha}_{t}(s) \hat{\beta}_{t}(s) \tag{9}$$

å…¶ä¸­

$p(l|x) = Z_{t} \stackrel{\text { def }}{=} \sum_{s=1}^{\left|1^{\prime}\right|} \frac{\hat{\alpha}_{t}(s) \hat{\beta}_{t}(s)}{y_{1_{s}^{t}}^{t}} \tag{10}$ 

å’Œå³è¾¹çš„

$ \sum_{s \in lab(l,k)} \alpha_t(s) \beta_t(x) \tag{11}$

æ˜¯ä¸ä¸€æ ·çš„ï¼Œå› ä¸ºå¼11 æ˜¯å»ºç«‹ä¸€ä¸ªå¤§å°ä¸ºã€æ˜ å°„è¡¨é•¿åº¦ï¼Œ è¾“å‡ºåºåˆ—åœºåœ°ã€‘çš„çŸ©é˜µï¼Œ ctcæ˜ å°„åçš„å­—ç¬¦ä¹‹å¤–çš„è®¾ä¸º0ï¼Œå…¶ä»–çš„æ ¹æ®$\hat{\alpha}_{t}(s) \hat{\beta}_{t}(s)$ç´¯åŠ ï¼Œè€Œ$p(l|x)$æ˜¯ä¸€ä¸ªå¸¸æ•°



å…·ä½“ä»£ç å‚ç…§ [stanford-ctc](https://github.com/d2rivendell/stanford-ctc)

```python
#params ä¸ºè¾“å‡ºåºåˆ— (n, m) nä¸ºæ˜ å°„è¡¨ä¸­å­—æ¯è¡¨ä¸ªæ•°ï¼Œ mä¸ºè¾“å‡ºåºåˆ—ä¸ªæ•°
# L ä¸º L = 2 * çœŸå®è¯æ±‡é•¿åº¦ + 1
grad = np.zeros(params.shape) # åŒ…å«äº†å…¶æ‰€ä»¥çš„å­—æ¯
ab = alphas * betas #å’ŒçœŸå®è¯æ±‡çš„å­—æ¯æœ‰å…³
for s in xrange(L):
    # blank
    if s % 2 == 0:
        grad[blank, :] += ab[s, :]
        ab[s, :] = ab[s, :] / params[blank, :]
    else:
        grad[seq[(s - 1) / 2], :] += ab[s, :]
        ab[s, :] = ab[s, :] / (params[seq[(s - 1) / 2], :])
absum = np.sum(ab, axis=0)#å¸¸æ•°
grad = params - grad / (params * absum)
```



## Beam search decoding

è§£ç æ˜¯åœ¨ é¢„æµ‹é˜¶æ®µï¼Œ

> ç¬¦å·è¡¨ç¤ºï¼š
>
> $\rho$:  å»é™¤äº†ç©ºæ ¼å’Œé‡å¤å­—ç¬¦çš„è¾“å‡ºæ ‡ç­¾åºåˆ—
>
> $\rho^e$:å­—ç¬¦ä¸²$\rho$çš„ç»“å°¾å­—ç¬¦
>
> $\hat{\rho}$:å­—ç¬¦ä¸²$\rho$ é™¤å»ç»“å°¾$\rho^e$åçš„å­—ç¬¦
>
> $\gamma(\rho, t)$: åœ¨tæ—¶åˆ»ç½‘ç»œè¾“å‡ºçš„å‡è®¾åºåˆ—ä¸º$\rho$(å·²ç»å»é™¤ç©ºæ ¼å’ŒæŠ˜å )çš„æ¦‚ç‡
>
> $\gamma^{-1}(\rho, t)$:   $t$æ—¶åˆ»ç½‘ç»œè¾“å‡ºblankç©ºå­—ç¬¦, è¾“å‡ºæ ‡ç­¾åºåˆ—ä¸º$\rho$çš„æ¦‚ç‡
>
> $\gamma^{+1}(\rho, t)$:   $t$æ—¶åˆ»ç½‘ç»œè¾“å‡ºéç©ºå­—ç¬¦,è¾“å‡ºæ ‡ç­¾åºåˆ—ä¸º$\rho$çš„æ¦‚ç‡



å®šä¹‰ï¼š

$$\gamma(\rho, t) = \gamma^{-1}(\rho, t) + \gamma^{+1}(\rho, t) \tag{12}$$



$$\gamma^{-1}(\rho, t) = \gamma(\rho, t - 1) y_b^t \tag{13}$$

$y_b^t $è¡¨ç¤º$t$æ—¶åˆ»è¾“å‡ºblankç©ºå­—ç¬¦çš„æ¦‚ç‡



#### ç–‘é—®ï¼š

ä¸ºä»€ä¹ˆè¦åŒºåˆ†tæ—¶åˆ»çš„å­—ç¬¦æ˜¯ä¸æ˜¯ç©ºçš„å‘¢ï¼Ÿ å¦‚æœæ˜¯ä¸ºäº†æŠ˜å å’Œå»ç©ºæ ¼ï¼Œ  ä¸ºä»€ä¹ˆä¸åŒºåˆ†tæ—¶åˆ»çš„å­—ç¬¦å’Œ$\rho^e$ç›¸ç­‰çš„æƒ…å†µ?

ç­”æ¡ˆå½“ç„¶ä¸æ˜¯ä¸ºäº†æŠ˜å å’Œå»é‡ã€‚ ä¸‹é¢çš„è®¨è®ºä¼šç»™å‡ºç­”æ¡ˆ

#### å¸¸è§„æŸç®—æ³•ï¼š

å¸¸è§„æŸç®—æ³•åœ¨æ¯ä¸ªè¾“å‡ºä¸­è®¡ç®—å½“å‰çš„å‡è®¾è·¯å¾„ï¼Œ å½“å‰å‡è®¾è·¯å¾„æ˜¯åŸºäºä¸Šä¸ªå‡è®¾è·¯å¾„ï¼Œè€Œä¸”ä¸æŠ˜å é‡å¤å­—ç¬¦å’Œç§»é™¤ç©ºæ ¼ï¼Œç®—æ³•ä¼šé€‰æ‹©å…¶ä¸­å¾—åˆ†æœ€é«˜çš„å‡ ç§è·¯å¾„ä½œä¸ºå½“å‰è·¯å¾„ï¼Œå¦‚ä¸‹å›¾ï¼ˆalphabet of  $\{\epsilon, a, b\}$ and a beam size of threeï¼‰ï¼š

![beam_search](/images/beam_search.png)

å›¾ç‰‡[æ¥æº](https://distill.pub/2017/ctc/)ï¼ˆä¸‹åŒï¼‰

#### æ”¹è¿›æŸç®—æ³•ï¼š

ä¸Šé¢çš„ç®—æ³•æ— æ³• å¤„ç†å¤šä¸ªå¯¹é½æ˜ å°„åˆ°åŒä¸€è¾“å‡ºè¿™ç§æƒ…å†µï¼Œ  å¦‚æœè¦å¤„ç†å¤šä¸ªå¯¹é½æ˜ å°„åˆ°åŒä¸€è¾“å‡ºè¿™ç§æƒ…å†µ, å¤„ç†çš„æ–¹å¼æ˜¯ï¼šä¸ä¿ç•™æŸä¸­çš„å¯¹é½åˆ—è¡¨ï¼Œè€Œæ˜¯å­˜å‚¨æŠ˜å é‡å¤å­—ç¬¦å¹¶ç§»é™¤ç©ºæ ¼åçš„è¾“å‡ºå‰ç¼€ã€‚

ä½†æ˜¯ï¼Œç§»é™¤ç©ºæ ¼$\epsilon$ä¼šæœ‰ä¸ªé—®é¢˜ å¦‚ä¸‹å›¾ä¸­ï¼š

 T=2æ—¶åˆ» ç¬¬äºŒä¸ª$[a,a] \Rightarrow [a]$ ï¼Œ$[a , \epsilon] \Rightarrow [a]$ , æœ‰ä¸¤ç§åœºæ™¯å»é‡å’Œç§»é™¤ç©ºæ ¼$\epsilon$åéƒ½è¾“å‡ºè·¯å¾„ä¸º$a$, æŠŠè¯¥å‡è®¾è¾“å‡ºè·¯å¾„å’Œæ¦‚ç‡å­˜å‚¨èµ·æ¥

 T=3æ—¶åˆ»ï¼Œå¦‚æœç¢°åˆ°ç»“åˆçš„è¿˜æ˜¯$a$ï¼Œç»“åˆä¸Šä¸€ä¸ªè¾“å‡º$a$ï¼Œå²‚ä¸æ˜¯ä¹Ÿæ˜¯$[a,a] \Rightarrow [a]$ ï¼Ÿï¼Œçœ‹æ ·å­å¥½åƒæ²¡æœ‰é—®é¢˜ï¼Œä½†æ˜¯åœ¨T=2æ—¶åˆ»å‡è®¾è¾“å‡ºè·¯å¾„$a$ çš„æ‰€æœ‰æœªæŠ˜å è·¯å¾„ä¸­æœ‰ä¸€ä¸ªæ˜¯ï¼š$[a , \epsilon] \Rightarrow [a]$  æœ€åä¸€ä¸ªæ˜¯ç©ºæ ¼ï¼Œå‡è®¾æˆ‘ä»¬åœ¨T=2æ—¶åˆ»ä¸ä½œæŠ˜å å»ç©ºæ ¼æ“ä½œï¼Œç»“åˆT=3æ—¶åˆ»çš„$a$: $[a , \epsilon, a] \Rightarrow [aa]$ , æœ¬æ¥æ˜¯è¾“å‡º$[aa]$çš„å‘€ï¼Œå´å› ä¸ºæŠ˜å å»ç©ºæ ¼æ“ä½œå˜æˆè¾“å‡º$[a]$, å› ä¸ºè¿™ä¸ªè¿‡ç¨‹ä¸­ç¼ºå¤±äº†è·¯å¾„ä¸­æœ€åä¸€ä¸ªä¸ºç©ºæ ¼çš„ä¿¡æ¯ã€‚ ä¸‹å›¾ä¸­T=3ä¸­$a$ç»“åˆ$a$, ä¼šç”ŸæˆT=4ä¸­$[a], [aa]$ä¸¤ä¸ªè·¯å¾„

![beam_search2](/images/beam_search_2.png)

ä¸ºäº†å®ç°ä¸Šå›¾çš„è¾“å‡ºæ•ˆæœï¼Œéœ€è¦æ€ä¹ˆåšå‘¢ï¼Œå¦‚ä¸‹å›¾ï¼š

![beam_search2](/images/beam_search_3.png)



æˆ‘ä»¬åªéœ€ç»Ÿè®¡ä¹‹å‰ä»¥ç©ºç™½æ ‡è®°$\epsilon$ç»“å°¾çš„æ‰€æœ‰è·¯å¾„çš„æ¦‚ç‡ï¼ˆä½äºå­—ç¬¦ä¸­é—´çš„$\epsilon$ä¹Ÿè¦ç»Ÿè®¡ï¼‰ã€‚åŒæ ·çš„ï¼Œå¦‚æœæ˜¯æ‰©å±•åˆ°$[a]$ï¼Œé‚£æˆ‘ä»¬è®¡ç®—çš„å°±æ˜¯ä¸ä»¥$\epsilon$ç»“å°¾çš„æ‰€æœ‰è·¯å¾„æ¦‚ç‡ã€‚æˆ‘ä»¬éœ€è¦è·Ÿè¸ªå½“å‰è¾“å‡ºåœ¨æœç´¢æ ‘ä¸­å‰ä¸¤å¤„è¾“å‡ºã€‚æ— è®ºæ˜¯ä»¥Ïµç»“å°¾è¿˜æ˜¯ä¸ä»¥Ïµç»“å°¾ï¼Œå¦‚æœæˆ‘ä»¬åœ¨å‰ªææ—¶ä¸ºæ¯ä¸€ç§å‡è®¾åšå¥½å¾—åˆ†æ’åºï¼Œæˆ‘ä»¬å°±èƒ½åœ¨è®¡ç®—ä¸­ä½¿ç”¨ç»„åˆåˆ†æ•°ã€‚



å°±å¾—å‡ºå…¬å¼:

$$\gamma(\rho, t) = \gamma^{-1}(\rho, t) + \gamma^{+1}(\rho, t) \tag{12}$$

â€‹    $$\gamma^{-1}(\rho, t) = \gamma(\rho, t - 1) y_b^t \tag{13}$$

â€‹           $$\gamma^{+}(\rho, t)=\gamma^{+}(\rho, t-1) y_{\rho^{e}}^{t}+\left\{\begin{array}{l}{\gamma(\hat{\rho}, t-1) y_{\rho^e}^{t}, \quad if\quad \rho^{\mathrm{e}} \neq \hat{\rho}^{e}} \\ {\gamma^{-}(\hat{\rho}, t-1) y_{\rho^e}^{t} ,  if\quad \rho^{\mathrm{e}} == \hat{\rho}^{e}} \tag{14} \end{array}\right.$$

#### å…¬å¼åˆ†æ

1. ä¸Šå¼13ä¸­$\gamma(\rho, t - 1) y_b^t$å’Œå¼14çš„**åŠ å·å·¦è¾¹**$\gamma^{+1}(\rho, t - 1) y_{\rho^e}^t$è¡¨ç¤ºäº†$t$æ—¶åˆ»å’Œ$t-1$æ—¶åˆ»çš„æŠ˜å è¾“å‡ºæ˜¯**ä¸€æ ·**çš„ã€‚åˆ†åˆ«è¡¨ç¤ºï¼š

   $t-1$æ—¶åˆ»çš„æŠ˜å å­—ç¬¦å’Œ $t$æ—¶åˆ»ç©ºæ ¼ç»„åˆæˆçš„è·¯å¾„ æŠ˜å åä¸å˜çš„æ¦‚ç‡ï¼ˆå¦‚ä¸Šæ‰€è¯´éœ€è¦è®°å½•ï¼‰  å’Œ   $t-1$æ—¶åˆ»çš„kå­—ç¬¦(éç©ºæ ¼)ç»„åˆè€Œæˆçš„æŠ˜å å­—ç¬¦å’Œ $t$æ—¶åˆ»ç›¸åŒçš„kå­—ç¬¦åˆæˆçš„è·¯å¾„æŠ˜å åä¸å˜çš„æ¦‚ç‡ã€‚æœ‰ç‚¹æ‹—å£ğŸ˜…



2. å¼14**åŠ å·å³è¾¹**è¡¨ç¤ºäº†$t$æ—¶åˆ»å’Œ$t-1$æ—¶åˆ»çš„æŠ˜å è¾“å‡ºæ˜¯**ä¸ä¸€æ ·**ï¼Œ æœ‰ä¸¤ç§æƒ…å†µï¼Œè€Œä¸”æ˜¯äº’æ–¥çš„ï¼š

â€‹       1).  å½“$t-1$æ—¶åˆ»çš„æŠ˜å è·¯å¾„(æ³¨æ„æ˜¯æŠ˜å è¿‡çš„)çš„æœ€åä¸€ä¸ªå­—ç¬¦å­—ç¬¦(éç©º)å’Œ$t$æ—¶åˆ»çš„å­—ç¬¦ä¸ä¸€æ ·æ—¶ï¼Œ è‚¯å®šä¼šç”Ÿæˆä¸åŒæŠ˜å è¾“å‡º, ä¾‹å¦‚: 

â€‹      $t-1$æ—¶åˆ»:

â€‹       $[a,b] \Rightarrow ab$ï¼Œ   $[ab,\epsilon] \Rightarrow ab$

â€‹       $t$æ—¶åˆ», ä¸èƒ½æ˜¯$b$ :

â€‹      $[ab, c] \Rightarrow abc$

â€‹       2).  å½“$t-1$æ—¶åˆ»çš„æŠ˜å è·¯å¾„(æ³¨æ„æ˜¯æŠ˜å è¿‡çš„)çš„æœ€åä¸€ä¸ªå­—ç¬¦å­—ç¬¦å’Œ$t$æ—¶åˆ»çš„å­—ç¬¦ä¸€æ ·æ—¶ï¼ˆéç©ºï¼‰ï¼Œ åªæœ‰è·Ÿ$t-1$æ—¶åˆ»çš„ç»„åˆå­—ç¬¦æ˜¯ç©ºæ ¼æ—¶æ‰èƒ½ä¿è¯$t$æ—¶åˆ»çš„æŠ˜å è·¯å¾„æ˜¯ä¸ä¸€æ ·çš„, ä¾‹å¦‚:

 $t-1$æ—¶åˆ»:

â€‹          $[ab,e] \Rightarrow ab$  (ç»“åˆç©ºå­—ç¬¦)ï¼Œ    $[ab,b] \Rightarrow ab$ (ç»“åˆéç©ºå­—ç¬¦)

 $t$æ—¶åˆ» åªæœ‰ç»“åˆ$t-1$æ—¶åˆ»çš„ç©ºå­—ç¬¦æ‰èƒ½æœ‰ä¸ä¸€æ ·çš„æŠ˜å è·¯å¾„ï¼š

â€‹         $ [ab,e,b ]  \Rightarrow [abb]$





```python
#https://github.com/githubharald/CTCDecoder
class BeamEntry:
	"information about one single beam at specific time-step"
  #å­˜å‚¨å”¯ä¸€æŠ˜å è·¯å¾„çš„ä¿¡æ¯ ä¿å­˜ç€æœªæŠ˜å å‰æœ€åä¸€ä¸ªç©ºå­—ç¬¦æ¦‚ç‡ï¼ŒæœªæŠ˜å å‰æœ€åä¸€ä¸ªéç©ºå­—ç¬¦æ¦‚ç‡
	def __init__(self):
		self.prTotal = 0 # blank and non-blank å¯¹åº”å…¬å¼12
		self.prNonBlank = 0 # non-blank
		self.prBlank = 0 # blank å¯¹åº”å…¬å¼13
		self.prText = 1 # LM score æœ‰è¯­è¨€æ¨¡å‹æ—¶æ‰æœ‰ç”¨
		self.lmApplied = False # flag if LM was already applied to this beam æœ‰è¯­è¨€æ¨¡å‹æ—¶æ‰æœ‰ç”¨
		self.labeling = () # beam-labeling

    
class BeamState:
	"information about the beams at specific time-step"
  # å­˜å‚¨æ‰€æœ‰æŠ˜å åçš„è¾“å‡ºè·¯å¾„
	def __init__(self):
		self.entries = {}

	def norm(self):
		"length-normalise LM score"
		for (k, _) in self.entries.items():
			labelingLen = len(self.entries[k].labeling)
			self.entries[k].prText = self.entries[k].prText ** (1.0 / (labelingLen if labelingLen else 1.0))

	def sort(self):
		"return beam-labelings, sorted by probability"
    #æ‰¾å‡ºæ¦‚ç‡æœ€å¤§çš„å‰ beam sizä¸ªæŠ˜å åçš„è¾“å‡ºè·¯å¾„
		beams = [v for (_, v) in self.entries.items()]
		sortedBeams = sorted(beams, reverse=True, key=lambda x: x.prTotal*x.prText)
		return [x.labeling for x in sortedBeams]


def applyLM(parentBeam, childBeam, classes, lm):
	"calculate LM score of child beam by taking score from parent beam and bigram probability of last two chars"
	if lm and not childBeam.lmApplied:
		c1 = classes[parentBeam.labeling[-1] if parentBeam.labeling else classes.index(' ')] # first char
		c2 = classes[childBeam.labeling[-1]] # second char
		lmFactor = 0.01 # influence of language model
		bigramProb = lm.getCharBigram(c1, c2) ** lmFactor # probability of seeing first and second char next to each other
		childBeam.prText = parentBeam.prText * bigramProb # probability of char sequence
		childBeam.lmApplied = True # only apply LM once per beam entry


def addBeam(beamState, labeling):
	"add beam if it does not yet exist"
  # æ²¡æœ‰åœ¨å­—å…¸é‡Œé¢ç®¡ç†çš„ï¼Œå°±ç•™ä¸ªä½ç½®ç»™å®ƒ
	if labeling not in beamState.entries:
		beamState.entries[labeling] = BeamEntry()


def ctcBeamSearch(mat, classes, lm, beamWidth=25):
	"beam search as described by the paper of Hwang et al. and the paper of Graves et al."

	blankIdx = len(classes)
	maxT, maxC = mat.shape

	# initialise beam state
  #æ²¡æœ‰å¼€å§‹ä¹‹å‰ æœ€å¼€å§‹çš„å…ˆé»˜è®¤æ”¾ä¸ªç©ºå­—ç¬¦ï¼ŒprBlankçš„æ¦‚ç‡è‚¯å®šæ˜¯100%
	last = BeamState()
	labeling = ()
	last.entries[labeling] = BeamEntry()
	last.entries[labeling].prBlank = 1
	last.entries[labeling].prTotal = 1

	# go over all time-steps
	for t in range(maxT):
		curr = BeamState()

		# get beam-labelings of best beams ä¸ºäº†å‡å°è®¡ç®—é‡ï¼Œéœ€è¦å‡æï¼Œåªå¯¹å‰beamWidthä¸ªæ„Ÿå…´è¶£
		bestLabelings = last.sort()[0:beamWidth]

		# go over best beams
		for labeling in bestLabelings:

			# å…ˆè®¡ç®—å’Œä¸Šä¸ªæ—¶é—´èŠ‚ç‚¹è¾“å‡ºæŠ˜å åºåˆ—ç›¸åŒï¼Œ ä¸”æœ€åä¸€ä¸ªå­—ç¬¦ä¸ä¸ºç©ºæ ¼çš„æ¦‚ç‡ å…¬å¼14åŠ å·å·¦è¾¹
			prNonBlank = 0
			# in case of non-empty beam
			if labeling:
				# probability of paths with repeated last char at the end
				prNonBlank = last.entries[labeling].prNonBlank * mat[t, labeling[-1]]

			# è®¡ç®—å’Œä¸Šä¸ªæ—¶é—´èŠ‚ç‚¹è¾“å‡ºæŠ˜å åºåˆ—ç›¸åŒï¼Œ ä¸”æœ€åä¸€ä¸ªå­—ç¬¦æ˜¯ç©ºæ ¼çš„æ¦‚ç‡ å…¬å¼13
			prBlank = (last.entries[labeling].prTotal) * mat[t, blankIdx]

			# add beam at current time-step if needed
			addBeam(curr, labeling)

			# fill in data
			curr.entries[labeling].labeling = labeling
			curr.entries[labeling].prNonBlank += prNonBlank
			curr.entries[labeling].prBlank += prBlank
			curr.entries[labeling].prTotal += prBlank + prNonBlank
			curr.entries[labeling].prText = last.entries[labeling].prText # beam-labeling not changed, therefore also LM score unchanged from
			curr.entries[labeling].lmApplied = True # LM already applied at previous time-step for this beam-labeling

			# å…ˆè®¡ç®—å’Œä¸Šä¸ªæ—¶é—´èŠ‚ç‚¹è¾“å‡ºæŠ˜å åºåˆ—ç›¸åŒçš„çš„æ¦‚ç‡
			for c in range(maxC - 1):#æ³¨æ„ï¼Œ å·²ç»é™¤å»äº†ç©ºå­—ç¬¦ï¼Œcè‚¯å®šéç©º
				# add new char to current beam-labeling
				newLabeling = labeling + (c,)

				# if new labeling contains duplicate char at the end, only consider paths ending with a blank
        #è®¡ç®—å’Œä¸Šä¸ªæ—¶é—´èŠ‚ç‚¹è¾“å‡ºæŠ˜å åºåˆ—ä¸ç›¸åŒçš„æ¦‚ç‡ å…¬å¼14åŠ å·å³è¾¹
				if labeling and labeling[-1] == c:
          #åªæœ‰ç»“åˆt-1æ—¶åˆ»çš„ç©ºå­—ç¬¦æ‰èƒ½æœ‰ä¸ä¸€æ ·çš„æŠ˜å è·¯å¾„
					prNonBlank = mat[t, c] * last.entries[labeling].prBlank
				else:
          # å½“å‰å­—ç¬¦å’Œt-1æ—¶åˆ»çš„æŠ˜å è·¯å¾„æœ€åä¸€ä¸ªå­—ç¬¦ï¼ˆå¿…å®šéç©ºï¼‰ä¸åŒæ—¶ï¼Œç»“åˆc(éç©º)å°±ä¼šè¾“å‡ºä¸åŒçš„æŠ˜å è·¯å¾„
					prNonBlank = mat[t, c] * last.entries[labeling].prTotal

				# add beam at current time-step if needed
				addBeam(curr, newLabeling)
				
				# fill in data
				curr.entries[newLabeling].labeling = newLabeling
				curr.entries[newLabeling].prNonBlank += prNonBlank
				curr.entries[newLabeling].prTotal += prNonBlank
				
				# åº”ç”¨è¯­è¨€æ¨¡å‹ï¼Œå¦‚æœæœ‰çš„è¯
				applyLM(curr.entries[labeling], curr.entries[newLabeling], classes, lm)

		# set new beam state
		last = curr

	# normalise LM scores according to beam-labeling-length
	last.norm()

	 # sort by probability
	bestLabeling = last.sort()[0] # get most probable labeling

	# map labels to chars
	res = ''
	for l in bestLabeling:
		res += classes[l]

	return res

```





å‚è€ƒï¼š

https://blog.csdn.net/JackyTintin/article/details/79425866

[åŸè®ºæ–‡](http://www.cs.toronto.edu/~graves/icml_2006.pdf)

[åŠ¨æ€ppt](https://docs.google.com/presentation/d/12gYcPft9_4cxk2AD6Z6ZlJNa3wvZCW1ms31nhq51vMk/pub?start=false&loop=false&delayms=3000&slide=id.g24e9f0de4f_0_19958)

https://www.cnblogs.com/shiyublog/p/10493348.html#_label2_0

https://xiaodu.io/ctc-explained-part2/

https://distill.pub/2017/ctc/

https://stats.stackexchange.com/questions/320868/what-is-connectionist-temporal-classification-ctc